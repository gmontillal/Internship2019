{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brown Scholars Internship 2019-2020 - Urban Wildlife in NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New York City is home to many diverse species of wildlife that arrived or existed long before humans settled here.\n",
    "In October 2016, Mayor Bill de Blasio launched WildlifeNYC, a citywide education and awareness campaign teaching New Yorkers how to live safely and responsibly alongside wild animals including deer, raccoons, and coyotes.\n",
    "\n",
    "Urban wildlife is any wild animal that lives in an urban environment, such as New York City. Urban wildlife includes birds, mammals, reptiles, fish and amphibians. Some urban wildlife is native, like eastern grey squirrels, while some are non-native, like mute swans. Domesticated and companion animals, like dogs, exotic pets, and farm animals are not considered urban wildlife. Domesticated but feral animals like pigeons and stray cats are also not considered urban wildlife.\n",
    "\n",
    "Data source: https://data.cityofnewyork.us/Environment/Urban-Park-Ranger-Animal-Condition-Response/fuhs-xmg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll start by importing packages we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then import the data. For now, the csv file should be in the same directory as the notebook. Notice that we are importing the date and time info as type 'datetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Urban_Park_Ranger_Animal_Condition_Response.csv',\n",
    "                   parse_dates = ['Date and Time of initial call', 'Date and time of Ranger response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you want to export the data, use df.to_csv(filename), where df is the name of your dataframe and filename is the name of the file where you want to save the data. The csv file will get created in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Viewing and inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded, let's check it out. To learn more about what the data looks like we can try the following commands:\n",
    "- data.head( ) - to look at the first 5 rows\n",
    "- data.tail( ) - to look at the last 5 rows\n",
    "- data.shape - to get the number of rows and columns\n",
    "- data.info( ) - to get the names of the columns, how many non null pieces of data is in each column, and the type of data in each column\n",
    "- data.nunique( ) - to get how many unique values are in each column\n",
    "- data.max() - to get the highest value in each column\n",
    "- data.min() to get the lowest value in each column\n",
    "- data['col'].value_counts() - to get how many unique values are in a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we should have a sense of which columns may have null values. It may be or not be ok for a column to have null values. One way to replace null values with some other value is using, use data.fillna(x) where x is the value we want instead of the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the data may not be in 'standard' form, that is for example, having the strings 'yes', 'YES', and 'Yes' all be values contained in the same column. To verify that the data in a column is in 'standard' form, we can use data['column_name'].unique(). For example, what happens when we try data['Species Description'].unique()? What happens when we try data['Species Status'].unique()? To replace values, we can use data['column name'].replace('yes','Yes') to replace all 'yes' values with 'Yes' values (for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our data is in the shape that we need it to be, we can start exploring it. To learn more about what the data can tell us we'll try filtering and grouping it, also computating some basic statistics and making graphs. The decisions that we make when doing all this can be based on our knowledge of the topic, our curiosity to learn from the data, as well as informed by what we learn from the data (or all three!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter data, the following commands are useful:\n",
    "\n",
    "- data[col] - to work only with one column\n",
    "- data[data[col] > 7] - to extract rows that meet a particular criteria\n",
    "- data[(data[col] > 0.5) & (data[col] < 0.7)] - to extract rows that meet more than one criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To group data, the following commands are useful:\n",
    "- data[[col1, col2]] - to work with only some columns\n",
    "- data.groupby(col) - To group the data based on the values in one column\n",
    "- data.groupby([col1,col2]) - To group the data based on the values in more than one column\n",
    "- If we want to find out how big each group is, we can use use .size() to count the number of rows in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute some basic statistics we can use:\n",
    "- data.describe() - summary statistics for numerical columns\n",
    "- data.mean() - mean of all columns\n",
    "- data.median() - median of each column\n",
    "- data.std() - standard deviation of each column\n",
    "- data.corr() - to get the correlation between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize categorical data we can use:\n",
    "- g = data['col'].value_counts()\n",
    "- g.plot(x=g.index, y=g.values, kind = 'bar')or g.plot.pie(y='Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
